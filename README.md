# HW1: Модели линейной регрессии o(_￣ ▽ ￣_)ブ

(здесь должно быть введение про то что и так все знают -- что это дз1 и что мы анализируем цену машин, бла-бла, но я просто поставлю сердечки учебной программе и тем кто её ведёт)

❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤
❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤
❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤
❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤

## Что сделали

- Посмотрели на данные
- Сконвертнули что надо куда надо (ох уж этот `torque` конвертер)
- Заполнили пропуски (потому что так сказали, а потом уже было поздно (っ °Д °;)っ )
- Обучали всякие линейные регрессии с разными регуляризациями
- Конечно же их ~~бенчмаркали~~ проверяли по R^2/MSE/RMSE на трейне+тесте
- (Регуляризации оказались на удивление бесполезными на наших данных)
- Потом вспомнили про категориальные признаки, добавили их наконец
- Ура что-то стало лучше
- А вообще лучше бы от выбросов почистили, или попробовали предсказывать используя перцентили, но задания такого не было (а потом в конце было уже поздно сквозь весь пайплайн всё гонять)
- Поделали ФЕ. Нечаянно оверфитнулись. Логично. ಥ_ಥ

## Результаты:

| Model                                                                                 | Test $R^2$ | Test $RMSE$ | Test business_metric_in_10_percent (higher is better) | Test business_metric_underprediction (higher is better) |
| :------------------------------------------------------------------------------------ | :--------- | :---------- | :---------------------------------------------------- | :------------------------------------------------------ |
| **linreg_numeric_only_unscaled**                                                      | 0.6004     | 479260      | 24.40%                                                | 0.1657                                                  |
| **linreg_numeric_only_scaled**                                                        | 0.6004     | 479260      | 24.40%                                                | 0.1657                                                  |
| **lasso_numeric_only_scaled_alpha_0_1**                                               | 0.6004     | 479260      | 24.40%                                                | 0.1657                                                  |
| **lasso_gridsearch_10fold_numeric_scaled_best_alpha**                                 | 0.5868     | 487344      | 24.10%                                                | 0.1663                                                  |
| **elasticnet_gridsearch_10fold_numeric_scaled_best_params**                           | 0.5886     | 486283      | 24.80%                                                | 0.1658                                                  |
| **linreg_numeric_scaled_L0_top_5_coeffs**                                             | 0.5886     | 486322      | 25.30%                                                | 0.1585                                                  |
| **ridge_gridsearch_10fold_with_categories_and_name_scaled**                           | 0.4930     | 539832      | 24.90%                                                | 0.1731                                                  |
| **ridge_gridsearch_10fold_with_categories_no_name_scaled**                            | 0.6261     | 463601      | 23.80%                                                | 0.1680                                                  |
| **ridge_gridsearch_10fold_with_categories_no_name_with_fe_interactions_scaled**       | **0.7874** | **349617**  | **26.10%**                                            | **0.1939**                                              |
| **ridge_10fold_with_categories_no_name_with_fe_interactions_scaled_L0_top_25_coeffs** | 0.7714     | 362490      | 25.00%                                                | 0.1714                                                  |

## Что дало приросты

Нет, увы, не регуляризации дали нам приросты на тесте.

В основном, добавление фич: категориальные + потом ещё ФЕ.

# Что не удалось

Ещё более rigorously оценить разные варианты и сочетания предобработок -- какие-то варианты всплывали только под конец ДЗ, и прокидывать новые `df, X, y` переменные сквозь 90% всей проделанной предобработки с измененной маленькой деталью просто не хотелось уже.

И вообще сидеть в линейных моделях хоть и полезно (<3) особенно с образовательной точки зрения, но конкретно в таких задачах было бы интереснее с практической точки зрения делать всякие "optuna grid search вокруг Boosting-machine-of-lr-weakened-Weighted-KNN-with-custom-distance-kernel с регуляризацией максимизации ширины гауссианы при приемлемом качестве на трейне" (это то как я решал вступительную Kaggle Competition с соседней ФКН программы ИПИИ -- могу скинуть ipynb если интересно). По сути то же самое, только не линейные модели. Хотя, думаю, и да этого конечно же дойдём.

# По сервису

- Удобно = "Делает всё что надо и вылетает только в редких случаях, не находящихся в normal user story/workflow"
- Что получилось хорошо: В целом кастомная вкладка решает почти весь EDA. В целом всё что надо, всё есть.
- Что можно улучшить:
  - Evaluation можно было сделать получше конечно.
  - На главной (General) -- не визуализировал всякие "долевые" истории вроде fuel / owner / итп.
  - Это бы легко фиксилось кастомной вкладкой, но там нет поддержки спец аггрегаторных метрик вроде `count`.
  - Плюс кастомную вкладку можно было бы сделать дашбордом, где можно глядеть глазами на несколько сконструированных графиков одновременно.
- Насчет следующей версии: а она будет? Вот когда будет, тогда и запланирую улучшения :D

# Вместо заключения

❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤
❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤
❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤
❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤ ❤
